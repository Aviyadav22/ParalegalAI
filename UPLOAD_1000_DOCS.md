# Upload 1000 Documents - Quick Guide

## ‚úÖ System Status

All services are running with parallel processing enabled!

- ‚úÖ **Qdrant:** Running on port 6333
- ‚úÖ **Collector:** Running on port 8888
- ‚úÖ **Server:** Running on port 3001
- ‚úÖ **API Keys:** 4 Gemini keys configured
- ‚úÖ **Parallel Processing:** ENABLED (8 workers)

---

## üöÄ Upload via UI

### **Step 1: Access ParalegalAI**
Open in browser: `http://localhost:3001` (or your server IP)

### **Step 2: Navigate to Workspace**
1. Click on your workspace (e.g., "research")
2. Click "Upload Documents" button

### **Step 3: Select 1000 PDFs**
1. Click "Choose Files" or drag & drop
2. Select all 1000 PDF files
3. Click "Upload"

### **Step 4: Monitor Progress**
The system will automatically:
- ‚úÖ Process in batches of 100
- ‚úÖ Use 8 concurrent workers
- ‚úÖ Rotate between 4 API keys
- ‚úÖ Retry failed documents
- ‚úÖ Show progress in UI

---

## üìä Expected Performance

### **With 4 API Keys:**
- **Processing Rate:** 15-20 docs/second
- **1000 PDFs:** 50-65 seconds (~1 minute)
- **Batch Processing:** 10 batches of 100

### **What Happens:**
```
Upload 1000 PDFs
    ‚Üì
Split into 10 batches (100 each)
    ‚Üì
Process each batch with 8 workers
    ‚Üì
Rotate API keys automatically
    ‚Üì
Embed chunks (100 at a time)
    ‚Üì
Store in Qdrant + PostgreSQL
    ‚Üì
Complete!
```

---

## üîç Monitor Progress

### **Real-time Logs:**

**Terminal 1 - Server logs:**
```bash
tail -f /home/azureuser/server.log
```

**Terminal 2 - Collector logs:**
```bash
tail -f /home/azureuser/collector.log
```

### **Check Vector Count:**
```bash
curl -s http://localhost:6333/collections/research | jq '.result.vectors_count'
```

### **Check Document Count:**
```bash
PGPASSWORD=paralegalai_pass psql -h localhost -U paralegalai_user -d paralegalai -c "SELECT COUNT(*) FROM workspace_documents;"
```

---

## üìã What You'll See

### **In Server Logs:**
```
[Documents] Using PARALLEL processing for 100 documents
[ParallelProcessor] Processing 100 documents...
[ParallelProcessor] Concurrency: 8, Batch size: 100
[ParallelProcessor] Processing batch 1/1 (100 documents)
[Qdrant] Using parallel Gemini embedder with multiple API keys
[ParallelGeminiEmbedder] Initialized with 4 API key(s)
[ParallelGeminiEmbedder] Embedding 120 chunks...
[ParallelGeminiEmbedder] Split into 2 batches
[ParallelProcessor] Progress: 100.0% | Processed: 100 | Failed: 0 | Rate: 18.5 docs/sec
```

### **In UI:**
- Progress bar showing upload status
- Number of documents processed
- Success/failure count
- Estimated time remaining

---

## ‚ö†Ô∏è Important Notes

### **1. Browser Limits**
- Most browsers limit file selection to ~500-1000 files
- If you can't select all 1000, split into 2 batches of 500

### **2. Memory Management**
- System processes in batches to avoid memory issues
- Each batch is completed before next starts
- Safe for 1000+ documents

### **3. Rate Limiting**
- 4 API keys = 6,000 requests/minute
- Automatic rotation prevents rate limits
- Retry logic handles temporary failures

### **4. Resume Capability**
- If upload fails, you can retry
- System skips already-processed documents
- No duplicate processing

---

## üõ†Ô∏è Troubleshooting

### **Issue: Upload Stuck**

**Check logs:**
```bash
tail -50 /home/azureuser/server.log
```

**Look for:**
- Rate limit errors ‚Üí Wait 1 minute, retry
- Memory errors ‚Üí Reduce batch size in .env
- Network errors ‚Üí Check internet connection

### **Issue: Some Documents Failed**

**Check failed documents:**
```bash
grep "Failed to vectorize" /home/azureuser/server.log
```

**Solutions:**
- Re-upload failed documents
- Check PDF format (must have text)
- Verify file size (< 100MB per file)

### **Issue: Slow Processing**

**Check:**
```bash
# API key usage
grep "ApiKeyRotator" /home/azureuser/server.log | tail -20

# System resources
htop
```

**Solutions:**
- Verify all 4 API keys are working
- Check CPU usage (should be 60-80%)
- Check network speed

---

## ‚úÖ Verification After Upload

### **1. Check Total Documents:**
```bash
PGPASSWORD=paralegalai_pass psql -h localhost -U paralegalai_user -d paralegalai -c "SELECT COUNT(*) FROM workspace_documents WHERE \"workspaceId\" = (SELECT id FROM workspaces WHERE slug = 'research');"
```

### **2. Check Total Vectors:**
```bash
curl -s http://localhost:6333/collections/research | jq '.result'
```

### **3. Test Search:**
1. Go to workspace in UI
2. Ask a question
3. Verify relevant documents are returned

---

## üìä Performance Metrics

After upload completes, check:

### **Processing Statistics:**
```bash
grep "FINAL STATISTICS" /home/azureuser/server.log -A 10
```

### **API Key Usage:**
```bash
grep "ApiKeyRotator" /home/azureuser/server.log | grep "Initialized"
```

### **Embedding Performance:**
```bash
grep "ParallelGeminiEmbedder" /home/azureuser/server.log | grep "Successfully embedded"
```

---

## üéØ Expected Results

### **After uploading 1000 PDFs:**

‚úÖ **Database:**
- 1000 documents in `workspace_documents`
- ~120,000 vectors in Qdrant (120 chunks/doc avg)

‚úÖ **Performance:**
- Total time: 50-65 seconds
- Processing rate: 15-20 docs/sec
- Success rate: 98-99%

‚úÖ **Search:**
- Instant search results
- Relevant document retrieval
- Citation support

---

## üîÑ If You Need to Stop/Restart

### **Stop Services:**
```bash
# Stop server
lsof -ti:3001 | xargs kill -9

# Stop collector
lsof -ti:8888 | xargs kill -9

# Stop Qdrant (optional)
pkill qdrant
```

### **Restart Services:**
```bash
# Start Qdrant
/usr/local/bin/qdrant --config-path /home/azureuser/qdrant_config/config.yaml &

# Start Collector
cd /home/azureuser/paralegalaiNew/collector && node index.js > /home/azureuser/collector.log 2>&1 &

# Start Server
cd /home/azureuser/paralegalaiNew/server && node index.js > /home/azureuser/server.log 2>&1 &
```

---

## üìû Quick Commands

```bash
# Check service status
curl -s http://localhost:3001/api/ping

# Watch server logs
tail -f /home/azureuser/server.log

# Check vector count
curl -s http://localhost:6333/collections/research | jq '.result.vectors_count'

# Check document count
PGPASSWORD=paralegalai_pass psql -h localhost -U paralegalai_user -d paralegalai -c "SELECT COUNT(*) FROM workspace_documents;"

# Check API keys
grep "GEMINI_API_KEY_" /home/azureuser/paralegalaiNew/server/.env | wc -l
```

---

## ‚ú® You're Ready!

**System is configured and running with:**
- ‚úÖ 4 Gemini API keys
- ‚úÖ 8 concurrent workers
- ‚úÖ Parallel batch processing
- ‚úÖ Automatic retry logic
- ‚úÖ Progress tracking

**Go to UI and upload your 1000 PDFs!** üöÄ

**Expected time: ~1 minute** ‚ö°
